{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "手写数字识别_tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRNN9/cd+7Kd8GBJeICdAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiyao-zhao/Python-for-Maschinen-Learning/blob/main/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLFiwzyWqr5p"
      },
      "source": [
        "线性回归-连续值预测-1.线性回归 2. 逻辑回归（二分类） \n",
        "离散值-分类\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OzOCIGvZaMQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EpvhyQGZpc6",
        "outputId": "4d26fa3d-f096-4b34-8ef5-e7e563fc5155"
      },
      "source": [
        "def preprocess(x,y):\n",
        "  x = tf.cast(x,dtype=tf.float32)/255.\n",
        "  y = tf.cast(y,dtype=tf.int32)\n",
        "  return x,y\n",
        "\n",
        "\n",
        "(x,y),(x_test,y_test)=datasets.mnist.load_data()\n",
        "print('datasets:',x.shape,y.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets: (60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETp1RD12Z6k3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675515e3-9c98-4bb6-f113-55839c6351e4"
      },
      "source": [
        "batchsize = 128\n",
        "#xs = tf.convert_to_tensor(xs,dtype=tf.float32)/255.\n",
        "#ys = tf.convert_to_tensor(ys,dtype=tf.int32)\n",
        "#y = tf.one_hot(y,depth=10)\n",
        "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "db = db.map(preprocess).shuffle(10000).batch(batchsize)\n",
        "\n",
        "db_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
        "db_test = db_test.map(preprocess).batch(batchsize)\n",
        "\n",
        "db_iter = iter(db)\n",
        "sample = next(db_iter)\n",
        "print('batch:',sample[0].shape,sample[1].shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: (128, 28, 28) (128,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxlsi0Y6anJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87932a46-227c-45d5-f687-5e924ae4181f"
      },
      "source": [
        "model = keras.Sequential([\n",
        "                          layers.Dense(512,activation='relu'),\n",
        "                          layers.Dense(256,activation='relu'),\n",
        "                          layers.Dense(128,activation='relu'),\n",
        "                          layers.Dense(64,activation='relu'),\n",
        "                          layers.Dense(10)\n",
        "            \n",
        "])\n",
        "\n",
        "model.build(input_shape=[None,28*28])\n",
        "model.summary()\n",
        "optimizer = optimizers.Adam(lr=1e-3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 575,050\n",
            "Trainable params: 575,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A8tVjSdytr9",
        "outputId": "0a0d9bcd-870c-4b90-822f-fb16f35af999"
      },
      "source": [
        "def main():\n",
        "#optimizer =optimizers.SGD(learning_rate=0.001)\n",
        "\n",
        "#def train_epoch(epoch):\n",
        "  for epoch in range(5):\n",
        "    \n",
        "    for step,(x,y) in enumerate(db):\n",
        "      x = tf.reshape(x,[-1,28*28])\n",
        "      \n",
        "      with tf.GradientTape() as tape:\n",
        "        logits=model(x)\n",
        "        y_onehot=tf.one_hot(y,depth=10)\n",
        "        loss_mse= tf.reduce_mean(tf.losses.MSE(y_onehot,logits))\n",
        "        loss_ce= tf.losses.categorical_crossentropy(y_onehot,logits,from_logits=True)\n",
        "        loss_ce= tf.reduce_mean(loss_ce)\n",
        "\n",
        "      grads=tape.gradient(loss_ce,model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
        "\n",
        "      if step % 100==0:\n",
        "        print(epoch,step, 'loss', float(loss_ce),float(loss_mse))\n",
        "    \n",
        "    #test\n",
        "    total_correct,total_num = 0.,0\n",
        "    for x,y in db_test:\n",
        "      x = tf.reshape(x,[-1,28*28])\n",
        "      logits = model(x)\n",
        "      prob = tf.nn.softmax(logits,axis=1)\n",
        "      pred = tf.argmax(prob,axis=1)\n",
        "      pred = tf.cast(pred, dtype=tf.int32)\n",
        "      correct = tf.equal(pred,y)\n",
        "      correct = tf.reduce_sum(tf.cast(correct,dtype=tf.int32))\n",
        "\n",
        "      total_correct += int(correct)\n",
        "      total_num += x.shape[0]\n",
        "\n",
        "    acc = total_correct/total_num\n",
        "    print(epoch,'test acc:',acc)\n",
        "\n",
        "if __name__=='__main__':\n",
        "  main()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 loss 0.04727201163768768 19.65355682373047\n",
            "0 100 loss 0.00931528676301241 26.714637756347656\n",
            "0 200 loss 0.07901075482368469 24.83548927307129\n",
            "0 300 loss 0.08683250844478607 25.064796447753906\n",
            "0 400 loss 0.07721150666475296 27.182273864746094\n",
            "0 test acc: 0.9745\n",
            "1 0 loss 0.08123013377189636 28.154521942138672\n",
            "1 100 loss 0.01036472711712122 32.96551513671875\n",
            "1 200 loss 0.03449293226003647 29.08911895751953\n",
            "1 300 loss 0.008725968189537525 30.90662384033203\n",
            "1 400 loss 0.007078244816511869 32.86140060424805\n",
            "1 test acc: 0.9747\n",
            "2 0 loss 0.027657099068164825 32.189292907714844\n",
            "2 100 loss 0.007016792893409729 34.42974853515625\n",
            "2 200 loss 0.035310111939907074 37.70127487182617\n",
            "2 300 loss 0.045026786625385284 37.193477630615234\n",
            "2 400 loss 0.06983201950788498 30.281307220458984\n",
            "2 test acc: 0.9788\n",
            "3 0 loss 0.057517316192388535 35.15782928466797\n",
            "3 100 loss 0.08328242599964142 45.74001693725586\n",
            "3 200 loss 0.004992438945919275 41.43646240234375\n",
            "3 300 loss 0.015180600807070732 40.531959533691406\n",
            "3 400 loss 0.015987547114491463 41.03639221191406\n",
            "3 test acc: 0.9735\n",
            "4 0 loss 0.02845359593629837 38.6655387878418\n",
            "4 100 loss 0.029124587774276733 49.65999221801758\n",
            "4 200 loss 0.01976158283650875 54.492889404296875\n",
            "4 300 loss 0.017025213688611984 40.90425109863281\n",
            "4 400 loss 0.007389184087514877 53.908538818359375\n",
            "4 test acc: 0.979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlodfmuItHxz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}